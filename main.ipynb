{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loading the dataset \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "cifar10 = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, cifar_data, patch_size=10, stride=8):\n",
    "        self.cifar_data = cifar_data\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.position_labels = {\n",
    "            (0, 0): 0, (0, 1): 1, (0, 2): 2,\n",
    "            (1, 0): 3,           (1, 2): 4,\n",
    "            (2, 0): 5, (2, 1): 6, (2, 2): 7\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cifar_data)\n",
    "    # this function allows to extract aone patch from the image \n",
    "    def extract_patch(self, img, top, left):\n",
    "        \"\"\"Extract a single patch from the image.\"\"\"\n",
    "        return img[:, top:top + self.patch_size, left:left + self.patch_size]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # loading the image \n",
    "        img, _ = self.cifar_data[idx]\n",
    "        img_size = img.size(1) # get the image size in our case is 32 by 32 \n",
    "\n",
    "        # Define and extract the reference center patch \n",
    "        center_top = (img_size - self.patch_size) // 2\n",
    "        center_left = (img_size - self.patch_size) // 2\n",
    "        reference_patch = self.extract_patch(img, center_top, center_left)\n",
    "\n",
    "        # Randomly select one of the eight possible neighboring patches\n",
    "        rel_pos = random.choice(list(self.position_labels.keys()))\n",
    "        offset_y, offset_x = rel_pos[0] - 1, rel_pos[1] - 1\n",
    "        neighbor_top = center_top + offset_y * self.stride\n",
    "        neighbor_left = center_left + offset_x * self.stride\n",
    "        neighbor_patch = self.extract_patch(img, neighbor_top, neighbor_left)\n",
    "\n",
    "        # Get the label based on the relative position\n",
    "        label = self.position_labels[rel_pos]\n",
    "\n",
    "        return reference_patch, neighbor_patch, label\n",
    "\n",
    "# DAtaloader \n",
    "patch_dataset = PatchDataset(cifar10)\n",
    "patch_loader = torch.utils.data.DataLoader(patch_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "image , label =cifar10[0]\n",
    "print(image.shape)\n",
    "patch_dataset.__getitem__(0)[0].shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
